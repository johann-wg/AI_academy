{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9장 - 합성곱 신경망 CNN\n",
    "---\n",
    "- 컨볼루션\n",
    "- 패딩 - 원본 이미지가 줄어드는 것을 방지하기 위해 덧대는 것\n",
    "- 스트라이드 - 몇 칸을 이동할지, 스트라이드가 `커질수록` 결과가 `작아짐`\n",
    "- **패딩한 상태**에서 <u>약수</u>를 구해서 스트라이드 할 것\n",
    "- `(H or W + 2p - FH) / S`\n",
    "\n",
    "- >풀링 - max pulling이 가장 결과가 좋다고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* np.expand_dims(변수, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_sc, x_test_sc = x_train / 255, x_test / 255\n",
    "x_train_sc = np.expand_dims(x_train_sc, axis=-1) # 흑백채널 하나\n",
    "x_test_sc = np.expand_dims(x_test_sc, axis=-1)\n",
    "print(x_train_sc.shape)\n",
    "print(x_test_sc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1D는 시계열, 3D는 동영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                100416    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,042\n",
      "Trainable params: 124,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1)) # 흑백채널 하나\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding='same')(inputs) # 필터 수, 커널사이즈\n",
    "x = MaxPooling2D((2,2), strides=2)(x)\n",
    "x = Conv2D(32, (3, 3), padding='same')(x) # 보통 처음 풀링 이후 activation 넣는다.\n",
    "x = MaxPooling2D((2,2), strides=2)(x)\n",
    "x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "\n",
    "x = Flatten()(x) # GlobalAverageFooling2D를 요즘 거의 많이 씀\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 28, 28, 128)       1280      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 14, 14, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 7, 7, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d_2 (Glo  (None, 256)              0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 467,338\n",
      "Trainable params: 466,314\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, Activation, GlobalMaxPooling2D\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1)) # 흑백채널 하나\n",
    "\n",
    "x = Conv2D(128, (3, 3), padding='same')(inputs) # 필터 수, 커널사이즈\n",
    "x = MaxPooling2D((2,2), strides=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), padding='same')(x) \n",
    "x = MaxPooling2D((2,2), strides=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = GlobalMaxPooling2D()(x) # GlobalAverageFooling2D를 요즘 거의 많이 씀 , 채널을 압축시켜줌\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model2 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 - 6s - loss: 0.2565 - accuracy: 0.9235 - val_loss: 0.0903 - val_accuracy: 0.9735 - 6s/epoch - 15ms/step\n",
      "Epoch 2/100\n",
      "375/375 - 2s - loss: 0.0634 - accuracy: 0.9806 - val_loss: 0.0550 - val_accuracy: 0.9837 - 2s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "375/375 - 2s - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0541 - val_accuracy: 0.9851 - 2s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "375/375 - 2s - loss: 0.0377 - accuracy: 0.9883 - val_loss: 0.0532 - val_accuracy: 0.9855 - 2s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "375/375 - 2s - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.0491 - val_accuracy: 0.9872 - 2s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "375/375 - 2s - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.0515 - val_accuracy: 0.9846 - 2s/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "375/375 - 2s - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.0471 - val_accuracy: 0.9871 - 2s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "375/375 - 2s - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.0504 - val_accuracy: 0.9873 - 2s/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "375/375 - 2s - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.0518 - val_accuracy: 0.9857 - 2s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "375/375 - 2s - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0532 - val_accuracy: 0.9878 - 2s/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "375/375 - 2s - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0605 - val_accuracy: 0.9872 - 2s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "375/375 - 2s - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0622 - val_accuracy: 0.9860 - 2s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ac622c220>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "stopper = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)\n",
    "model.fit(x_train_sc, y_train, epochs=100, batch_size=128, validation_split=0.2, callbacks=[stopper], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어제 한 결과보다 더 좋게 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0439 - accuracy: 0.9863\n",
      "loss:  0.043949194252491 acc:  0.986299991607666\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_acc = model.evaluate(x_test_sc, y_test)\n",
    "print('loss: ', eval_loss, 'acc: ', eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtCore import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class MyApp(QMainWindow):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image = QImage(QSize(400, 400), QImage.Format_RGB32)\n",
    "        self.image.fill(Qt.white)\n",
    "        self.drawing = False\n",
    "        self.brush_size = 30\n",
    "        self.brush_color = Qt.black\n",
    "        self.last_point = QPoint()\n",
    "        self.loaded_model = None\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        menubar = self.menuBar()\n",
    "        menubar.setNativeMenuBar(False)\n",
    "        filemenu = menubar.addMenu('File')\n",
    "\n",
    "        load_model_action = QAction('Load model', self)\n",
    "        load_model_action.setShortcut('Ctrl+L')\n",
    "        load_model_action.triggered.connect(self.load_model)\n",
    "\n",
    "        save_action = QAction('Save', self)\n",
    "        save_action.setShortcut('Ctrl+S')\n",
    "        save_action.triggered.connect(self.save)\n",
    "\n",
    "        clear_action = QAction('Clear', self)\n",
    "        clear_action.setShortcut('Ctrl+C')\n",
    "        clear_action.triggered.connect(self.clear)\n",
    "\n",
    "        filemenu.addAction(load_model_action)\n",
    "        filemenu.addAction(save_action)\n",
    "        filemenu.addAction(clear_action)\n",
    "\n",
    "        self.statusbar = self.statusBar()\n",
    "\n",
    "        self.setWindowTitle('MNIST Classifier')\n",
    "        self.setGeometry(300, 300, 400, 400)\n",
    "        self.show()\n",
    "\n",
    "    def paintEvent(self, e):\n",
    "        canvas = QPainter(self)\n",
    "        canvas.drawImage(self.rect(), self.image, self.image.rect())\n",
    "\n",
    "    def mousePressEvent(self, e):\n",
    "        if e.button() == Qt.LeftButton:\n",
    "            self.drawing = True\n",
    "            self.last_point = e.pos()\n",
    "\n",
    "    def mouseMoveEvent(self, e):\n",
    "        if (e.buttons() & Qt.LeftButton) & self.drawing:\n",
    "            painter = QPainter(self.image)\n",
    "            painter.setPen(QPen(self.brush_color, self.brush_size, Qt.SolidLine, Qt.RoundCap))\n",
    "            painter.drawLine(self.last_point, e.pos())\n",
    "            self.last_point = e.pos()\n",
    "            self.update()\n",
    "\n",
    "    def mouseReleaseEvent(self, e):\n",
    "        if e.button() == Qt.LeftButton:\n",
    "            self.drawing = False\n",
    "\n",
    "            arr = np.zeros((28, 28))\n",
    "            for i in range(28):\n",
    "                for j in range(28):\n",
    "                    arr[j, i] = 1 - self.image.scaled(28, 28).pixelColor(i, j).getRgb()[0] / 255.0\n",
    "            arr = arr.reshape(-1, 28, 28, 1)\n",
    "\n",
    "            if self.loaded_model:\n",
    "                pred = self.loaded_model.predict(arr)[0]\n",
    "                pred_num = str(np.argmax(pred))\n",
    "                self.statusbar.showMessage('숫자 ' + pred_num + '입니다.')\n",
    "\n",
    "    def load_model(self):\n",
    "        fname, _ = QFileDialog.getOpenFileName(self, 'Load Model', '')\n",
    "\n",
    "        if fname:\n",
    "            self.loaded_model = tf.keras.models.load_model(fname)\n",
    "            self.statusbar.showMessage('Model loaded.')\n",
    "\n",
    "    def save(self):\n",
    "        fpath, _ = QFileDialog.getSaveFileName(self, 'Save Image', '', \"PNG(*.png);;JPEG(*.jpg *.jpeg);;All Files(*.*) \")\n",
    "\n",
    "        if fpath:\n",
    "            self.image.scaled(28, 28).save(fpath)\n",
    "\n",
    "    def clear(self):\n",
    "        self.image.fill(Qt.white)\n",
    "        self.update()\n",
    "        self.statusbar.clearMessage()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    ex = MyApp()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
