{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    모델의 Body : 입력데이터에 따라\n",
    "- 다변량 데이터 (None, n_features) - Dense\n",
    "- 시계열 데이터 (None, seq_len, n_features) - RNN, **CNN(Conv1D)**\n",
    "- 이미지 데이터 (None, height, width, channels) - CNN(Conv2D)\n",
    "- 영상 데이터 (None, seq_len, height, width, channels) - CNN(Conv3D)\n",
    "---\n",
    "    모델의 Header : 출력데이터에 따라\n",
    "- 회귀 출력 - _____출력노드 1개   |   활성화함수 Linear   |   손실함수 MSE\n",
    "- 이진분류 출력 - 출력노드 1개   |  활성화함수 Sigmoid  |   손실함수 BCE\n",
    "- 다중분류 출력 - 출력노드 n_class |    활성화함수 Softmax  |   손실함수 CCE\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 차원 축소와 매니폴드 학습\n",
    "- RBF(radial basis function)\n",
    "- 매니폴드(다양체)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오토인코더와 잠재표현(latent) 학습\n",
    "- 오토인코더는 x와 y가 같다\n",
    "- 인코더 -> 압축(잠재latent 벡터) -> 디코더 -> 비교 오차 \n",
    "- 오토인코더 코드는 인터넷에 많으니 찾아서 수정\n",
    "- 사용법 - 인코더 부분만 떼어와서 body 동결, header 붙이고 사용 (전이학습)\n",
    "- 오토인코더에서 착안한 것이 diffusion\n",
    "- 오토인코더로 사전학습한 다음에 모델을 만드는 것이 효과가 더 좋음"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Encoder\n",
    "inputs = layers.Input(shape=(n_features,))\n",
    "x = layers.Dense(32, activation='relu')(inputs)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "ouputs = layers.Dense(latent_dims, activation='relu')(x) # activation 해도 되고 안 해도 되고\n",
    "\n",
    "encoder = Model(inputs=inputs, outputs=ouputs)\n",
    "\n",
    "# Decoder\n",
    "inputs = layers.Input(shape=(latent_dims,)) # 인코더의 출력을 받음\n",
    "x = layers.Dense(16, activation='relu')(inputs)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "outputs = layers.Dense(n_features)(x) # activation='linear'\n",
    "\n",
    "decoder = Model(inputs=inputs, outputs=ouputs)\n",
    "\n",
    "inputs = encoder.inputs\n",
    "latent = encoder.outputs\n",
    "outputs = decoder(latent)\n",
    "\n",
    "# AutoEncoder\n",
    "AE = Model(inputs=inputs, outputs=outputs)\n",
    "compile.....\n",
    "# 학습\n",
    "AE.fit(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
